{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Classifier Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, channel, in_len, out_len):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.fc1_size = in_len ** 2\n",
    "        self.fc2_size = self.fc1_size * 2\n",
    "        self.fc3_size = self.fc2_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc1_size, self.fc2_size)\n",
    "        self.fc2 = nn.Linear(self.fc2_size, self.fc3_size)\n",
    "        self.fc3 = nn.Linear(self.fc3_size, out_len)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "    def forward(self, x):\n",
    "        # Flatten input\n",
    "        x = x.view(x.shape[0],x.shape[1], -1)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        \n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_image(image):\n",
    "    \"\"\"\n",
    "    Break a multispectral image into 9x4x4 tensors\n",
    "    image: Pytorch tensor with dimensions CxHxW where in this application\n",
    "        C is channels, H is height, and W is width\n",
    "    returns:\n",
    "        image: numpy array representing \n",
    "        ground_truth: \n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    height = image[0].shape[0]\n",
    "    width = image[0].shape[1]\n",
    "    \n",
    "    for i in range(0, height, 4):\n",
    "        band_chunks = []\n",
    "\n",
    "        if i + 3 > height - 1:\n",
    "            break\n",
    "\n",
    "        for j in range(0, width, 4):\n",
    "            rows = []\n",
    "            \n",
    "            if j + 4 > width:\n",
    "                break\n",
    "                \n",
    "            for band in image:\n",
    "                chunk = np.ndarray(shape=(0))\n",
    "                #try:\n",
    "                half1 = np.append([band[i + 0][j:j + 4]], [band[i + 1][j:j + 4]], axis=0)\n",
    "                half2 = np.append([band[i + 2][j:j + 4]], [band[i + 3][j:j + 4]], axis=0)\n",
    "                #except:\n",
    "                #print(height, width)\n",
    "                #print(i, j)\n",
    "                #break\n",
    "                chunk = np.append(half1, half2, axis=0)\n",
    "\n",
    "                rows.append(chunk)\n",
    "\n",
    "            band_chunks.append(rows)\n",
    "\n",
    "        data.append(band_chunks)\n",
    "        \n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(9, 2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, filenames = load_data(10, \"./data/modis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [data[i][0] for i in range(len(data))]\n",
    "train_data = [data[i][1:] for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:30} shape: (batch, channel, height, width)\".format(\"filename\"))\n",
    "\n",
    "for index, image in enumerate(train_data):\n",
    "    chunked_image = np.reshape(chunk_image(image), (-1, 9, 4, 4))\n",
    "    print(\"{:30} shape: {}\".format(filenames[index], chunked_image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(torch.randn(32, 9, 2, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
